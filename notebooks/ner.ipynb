{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from wrapper import *\n",
    "from typing import List, Dict\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', sep='\\t')    # [700:900]\n",
    "pos_df = train_df#[train_df.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-cluener2020-chinese\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"uer/roberta-base-finetuned-cluener2020-chinese\")\n",
    "model.cuda()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "ner = pipeline('ner', model=model, tokenizer=tokenizer, device=device)\n",
    "pos_text = pos_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "d:\\Apps\\Anaconda3\\envs\\general-torch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3199: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "d:\\Apps\\Anaconda3\\envs\\general-torch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "ner_outputs = ner(inputs=pos_text.values.tolist())\n",
    "non_empty_idx = np.argwhere(ner_outputs).flatten()\n",
    "ntf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_ds(outputs:List[List[dict]]):\n",
    "    entity_vocab = {}\n",
    "    for output in outputs:\n",
    "        if output:\n",
    "            sentence_vocab = postprocess_sentence(output)\n",
    "            for k, v in sentence_vocab.items():\n",
    "                if k in entity_vocab.keys():\n",
    "                    for v_ in v:\n",
    "                        if v_ not in entity_vocab[k]:\n",
    "                            entity_vocab[k].append(v_) \n",
    "                else:\n",
    "                    entity_vocab[k] = v\n",
    "    return entity_vocab\n",
    "\n",
    "\n",
    "def postprocess_sentence(ner_outputs:List[dict]):\n",
    "    entity_vocab = {}\n",
    "    if ner_outputs == []:\n",
    "        return\n",
    "\n",
    "    current = ''\n",
    "    for out in ner_outputs:\n",
    "        if out['entity'][0] == 'B':\n",
    "            if len(current) > 1:\n",
    "                # if category == 'scene': print(current)\n",
    "                if category not in entity_vocab.keys():\n",
    "                    entity_vocab[category] = []\n",
    "                if current not in entity_vocab[category]:\n",
    "                    entity_vocab[category].append(current)\n",
    "            current = ''\n",
    "            category = out['entity'][2:]\n",
    "            current += out['word']\n",
    "        if out['entity'][0] == 'I':\n",
    "            if not current:\n",
    "                continue\n",
    "            current += out['word']\n",
    "    if len(current) > 1:\n",
    "        if category not in entity_vocab.keys():\n",
    "            entity_vocab[category] = []\n",
    "        if current not in entity_vocab[category]:\n",
    "            entity_vocab[category].append(current)\n",
    "    return entity_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id():\n",
    "    from shortid import ShortId\n",
    "    return ShortId().generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_vocab = postprocess_ds(ner_outputs)\n",
    "output_file_name = os.path.join(\"D:\\Apps\\Anaconda3\\envs\\general-torch\\Lib\\site-packages\", \"nlpcda\\data\\entities.txt\")\n",
    "\n",
    "with open(output_file_name, 'w', encoding='utf-8') as f:\n",
    "    for k, words in entity_vocab.items():\n",
    "        f.write(id() + '= ' + ' '.join(words) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('general-torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "664321c82ff6de4bb3d6cb89c025cd05a28d5519bb13940eaa668e3035d94110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
